{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77104494-f0df-4eaa-b8db-4d6d3150e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=QZUGSYSXCC1B19G38ETQ\n",
      "env: CLEARML_API_SECRET_KEY=qHCvroHchWwGmwAcCAhaFbBLUQ90BwxVW1qoMxifgMNkHAPsk3\n",
      "ClearML Task: created new task id=a72a59a972d541c1aa8874125735c96d\n",
      "2023-10-13 12:02:09,902 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/2eea372b5e60460e98ffcfcc4b47b092/experiments/a72a59a972d541c1aa8874125735c96d/output/log\n"
     ]
    }
   ],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=QZUGSYSXCC1B19G38ETQ\n",
    "%env CLEARML_API_SECRET_KEY=qHCvroHchWwGmwAcCAhaFbBLUQ90BwxVW1qoMxifgMNkHAPsk3\n",
    "from clearml import Task, Dataset\n",
    "task = Task.init(project_name='great project', task_name='Keras Research', output_uri = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2fcbaa-1045-48d6-998c-181c10f86090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668bd0b-3754-4e0f-bc25-d1c67a003543",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Dataset.get(dataset_name = \"np mnist data\", alias = \"np mnist data\").get_local_copy()\n",
    "print(data_path)\n",
    "\n",
    "train_data = np.load(f\"{data_path}/train_data.npy\")\n",
    "test_data = np.load(f\"{data_path}/test_data.npy\")\n",
    "noisy_test_data = np.load(f\"{data_path}/noisy_test_data.npy\")\n",
    "noisy_train_data = np.load(f\"{data_path}/noisy_train_data.npy\")\n",
    "y_train = np.load(f\"{data_path}/y_train.npy\")\n",
    "y_test = np.load(f\"{data_path}/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e197b02c-0c29-4b7b-aeb7-eb20a025dc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_directory = \"C:\\\\Users\\\\egors\\\\jupyter\"\n",
    "\n",
    "data_path = f\"{current_directory}\\\\files\"\n",
    "\n",
    "train_data = np.load(f\"{data_path}\\\\train_data.npy\")\n",
    "test_data = np.load(f\"{data_path}\\\\test_data.npy\")\n",
    "noisy_test_data = np.load(f\"{data_path}\\\\noisy_test_data.npy\")\n",
    "noisy_train_data = np.load(f\"{data_path}\\\\noisy_train_data.npy\")\n",
    "y_train = np.load(f\"{data_path}\\\\y_train.npy\")\n",
    "y_test = np.load(f\"{data_path}\\\\y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ac2c97-fc42-4ca8-ae7b-974738466359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e663c30-b7f0-4a9a-a27f-2d40a8d5bc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 35s 36ms/step - loss: 0.1432 - accuracy: 0.9567 - val_loss: 0.0462 - val_accuracy: 0.9846\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 0.0384 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "# Создание сверточной сети\n",
    "\n",
    "data = {\"batch_size\":64, \"epochs\":2, \"first layer filter\":5, \"second layer filter\":3, \"MaxPooling\":2}\n",
    "task.connect(data)\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, (data[\"first layer filter\"], data[\"first layer filter\"]), activation='relu')(input_img)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (data[\"second layer filter\"], data[\"second layer filter\"]), activation='relu')(x)\n",
    "x = MaxPooling2D((data[\"MaxPooling\"], data[\"MaxPooling\"]))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_img, output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, y_train_cat, batch_size = data[\"batch_size\"], epochs = data[\"epochs\"], validation_data=(test_data, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3276ccc-4a54-4674-aa8d-6c342433b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение графика функции потерь\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss') \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('loss_plot.png')\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy') \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Training_and_Validation_Accuracy.png')\n",
    "\n",
    "# Оценка производительности модели\n",
    "score = model.evaluate(test_data, y_test_cat, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69008268-89c1-4622-a94f-2bac8294c170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 238ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def plot_digits(*args):\n",
    "    args = [x.squeeze() for x in args]\n",
    "    n = min([x.shape[0] for x in args])\n",
    "    \n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\n",
    "    for j in range(n):\n",
    "        for i in range(len(args)):\n",
    "            ax = plt.subplot(len(args), n, i*n + j + 1)\n",
    "            plt.imshow(args[i][j])\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "n=5\n",
    "imgs = train_data[:n]\n",
    "for img in imgs:\n",
    "    prediction = model.predict(img.reshape(1, 28, 28, 1))\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    print(predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e84dc-678a-4293-a6f2-e1d816a04ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
